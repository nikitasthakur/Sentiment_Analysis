{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Data Preprocessing and Feature Engineering\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# !pip install tweet-preprocessor\n",
    "# !pip install textblob\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "#Model Selection and Validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBAMA = 'final-testData-no-label-Obama-tweets(1).xlsx'\n",
    "ROMNEY = 'final-testData-no-label-Romney-tweets(1).xlsx'\n",
    "df_obama = pd.read_excel(OBAMA, sheet_name=0, header=None,index_col=None, \n",
    "                   skiprows=[0,1], names=['tweet'])\n",
    "df_romney = pd.read_excel(ROMNEY, sheet_name=0, header=None,index_col=None, \n",
    "                   skiprows=[0,1], names=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(unclean_tweets):\n",
    "    cleaned_data = []\n",
    "    for tweet in unclean_tweets:\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(r'@\\w+', r'', tweet)\n",
    "        tweet = re.sub('<[^<]+?>', '', tweet)\n",
    "        tweet = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "        tweet = re.sub(r'(\\s)@\\w+', r'', tweet)\n",
    "        tweet = re.sub(r'[<>!#@$:.,%\\?-]+', r'', tweet)\n",
    "        tweet = tweet.replace(\"'\", \"\").replace(\"\\\"\",\"\")\n",
    "        words = nltk.word_tokenize(tweet.lower())\n",
    "        cleaned_data.append(words)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Cast the results column to string since it contains both 2 & '2'\n",
    "# df_obama['class'] = df_obama['class'].astype(str)\n",
    "# sns.countplot(x = 'class', data = df_obama)\n",
    "\n",
    "# df_romney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_romney['class'] = df_romney['class'].astype(str)\n",
    "# sns.countplot(x = 'class', data = df_romney)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop rows not having 0, 1, -1\n",
    "# df_obama = df_obama[df_obama['class'].isin(['0', '1', '-1'])] \n",
    "# df_romney = df_romney[df_romney['class'].isin(['0', '1', '-1'])] \n",
    "\n",
    "# # Print the shape of the dataframe \n",
    "# print(df_obama.shape) \n",
    "# print(df_romney.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(x = 'class', data = df_obama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obama['tweet'] = df_obama['tweet'].astype(str)\n",
    "df_obama['tweet_length'] = df_obama['tweet'].apply(lambda x: len(str(x)))\n",
    "\n",
    "df_romney['tweet'] = df_romney['tweet'].astype(str)\n",
    "df_romney['tweet_length'] = df_romney['tweet'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(tweet):\n",
    "    tweet = re.sub(re.compile('<[^>]+>'), '', tweet)\n",
    "    tweet_blob = TextBlob(tweet)\n",
    "    return ' '.join(tweet_blob.words)\n",
    "\n",
    "def clean_stopwords(tweet):\n",
    "    tweet_list = [ele for ele in tweet.split() if ele != 'user']\n",
    "    clean_tokens = [t for t in tweet_list if re.match(r'[^\\W\\d]*$', t)]\n",
    "    clean_s = ' '.join(clean_tokens)\n",
    "    clean_mess = [word for word in clean_s.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_mess\n",
    "\n",
    "# lexical normalization\n",
    "def normalization(tweet_list):\n",
    "    lem = WordNetLemmatizer()\n",
    "    normalized_tweet = []\n",
    "    for word in tweet_list:\n",
    "        normalized_text = lem.lemmatize(word,'v')\n",
    "        normalized_tweet.append(normalized_text)\n",
    "    return normalized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I actually like  &lt;e&gt;Romney &lt;/e&gt;'s response to ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[actually, like, Romney, response, immigration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just for that &lt;a&gt;immigration statement &lt;/a&gt;tha...</td>\n",
       "      <td>115</td>\n",
       "      <td>[immigration, statement, Romney, answer, enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This man  &lt;e&gt;Romney  &lt;/e&gt;is tearing this dude ...</td>\n",
       "      <td>68</td>\n",
       "      <td>[man, Romney, tear, dude, economics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;e&gt;Romney  &lt;/e&gt;had less to prove, given the la...</td>\n",
       "      <td>108</td>\n",
       "      <td>[Romney, less, prove, give, last, debate, back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;e&gt;Romney &lt;/e&gt;- he comes off as a dumbass, but...</td>\n",
       "      <td>160</td>\n",
       "      <td>[Romney, come, dumbass, love, plan, small, lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Great &lt;a&gt;closing&lt;/a&gt; by  &lt;e&gt;Romney &lt;/e&gt;. Summe...</td>\n",
       "      <td>77</td>\n",
       "      <td>[Great, close, Romney, Summed, well, debate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Just ready for  &lt;e&gt;Romney &lt;/e&gt; to become presi...</td>\n",
       "      <td>54</td>\n",
       "      <td>[ready, Romney, become, president, lol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Get him on his trampling on the Constitution, ...</td>\n",
       "      <td>65</td>\n",
       "      <td>[Get, trample, Constitution, Mitt, Please]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Go &lt;e&gt;Romney&lt;/e&gt;!!! I'm tired of all this &lt;a&gt;i...</td>\n",
       "      <td>68</td>\n",
       "      <td>[Go, Romney, tire, immigration, shit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;e&gt;Romney&lt;/e&gt; is the shit you people are crazy</td>\n",
       "      <td>46</td>\n",
       "      <td>[Romney, shit, people, crazy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  tweet_length  \\\n",
       "3   I actually like  <e>Romney </e>'s response to ...            58   \n",
       "4   Just for that <a>immigration statement </a>tha...           115   \n",
       "5   This man  <e>Romney  </e>is tearing this dude ...            68   \n",
       "6   <e>Romney  </e>had less to prove, given the la...           108   \n",
       "7   <e>Romney </e>- he comes off as a dumbass, but...           160   \n",
       "8   Great <a>closing</a> by  <e>Romney </e>. Summe...            77   \n",
       "9   Just ready for  <e>Romney </e> to become presi...            54   \n",
       "10  Get him on his trampling on the Constitution, ...            65   \n",
       "11  Go <e>Romney</e>!!! I'm tired of all this <a>i...            68   \n",
       "12     <e>Romney</e> is the shit you people are crazy            46   \n",
       "\n",
       "                                        tweet_cleaned  \n",
       "3     [actually, like, Romney, response, immigration]  \n",
       "4   [immigration, statement, Romney, answer, enoug...  \n",
       "5                [man, Romney, tear, dude, economics]  \n",
       "6   [Romney, less, prove, give, last, debate, back...  \n",
       "7   [Romney, come, dumbass, love, plan, small, lar...  \n",
       "8        [Great, close, Romney, Summed, well, debate]  \n",
       "9             [ready, Romney, become, president, lol]  \n",
       "10         [Get, trample, Constitution, Mitt, Please]  \n",
       "11              [Go, Romney, tire, immigration, shit]  \n",
       "12                      [Romney, shit, people, crazy]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obama['tweet_cleaned'] = df_obama['tweet'].apply(lambda x: normalization(clean_stopwords(clean_sentence(x))))\n",
    "df_obama.head(10)\n",
    "df_romney['tweet_cleaned'] = df_romney['tweet'].apply(lambda x: normalization(clean_stopwords(clean_sentence(x))))\n",
    "df_romney.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>tweet_clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ditto. I started @247LS 4 years ago. RT @bmorr...</td>\n",
       "      <td>146</td>\n",
       "      <td>[Ditto, start, years, ago, RT, bmorrissey, wor...</td>\n",
       "      <td>ditto i started 4 years ago rt i work for a sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I absolutely love &lt;e&gt;Obama&lt;/e&gt;'s view in &lt;a&gt;im...</td>\n",
       "      <td>125</td>\n",
       "      <td>[absolutely, love, Obama, view, immigration, r...</td>\n",
       "      <td>i absolutely love obamas view in immigration h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm agreeing completely with &lt;e&gt;Obama&lt;/e&gt;'s st...</td>\n",
       "      <td>132</td>\n",
       "      <td>[agree, completely, Obama, stance, immigration...</td>\n",
       "      <td>im agreeing completely with obamas stance on i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt;'s &lt;a&gt;smile&lt;/a&gt; makes me happy.</td>\n",
       "      <td>43</td>\n",
       "      <td>[Obama, smile, make, happy]</td>\n",
       "      <td>obamas smile makes me happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hahahahahaahahha&lt;e&gt; Obama&lt;/e&gt;'s &lt;a&gt;rebuttal&lt;/a...</td>\n",
       "      <td>83</td>\n",
       "      <td>[Hahahahahaahahha, Obama, rebuttal, get, actua...</td>\n",
       "      <td>hahahahahaahahha obamas rebuttal got actual cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If you think the economy has gotten worse duri...</td>\n",
       "      <td>153</td>\n",
       "      <td>[think, economy, get, worse, Obama, term, plea...</td>\n",
       "      <td>if you think the economy has gotten worse duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;e&gt;Obama&lt;/e&gt;'s &lt;a&gt;debate performance&lt;/a&gt; tonig...</td>\n",
       "      <td>91</td>\n",
       "      <td>[Obama, debate, performance, tonight, better, ...</td>\n",
       "      <td>obamas debate performance tonight about 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I like the fact that it's not within &lt;e&gt;Obama&lt;...</td>\n",
       "      <td>76</td>\n",
       "      <td>[like, fact, within, Obama, comfort, zone, rude]</td>\n",
       "      <td>i like the fact that its not within obamas com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>President &lt;e&gt;Obama&lt;/e&gt;'s &lt;a&gt;policies&lt;/a&gt; HAS N...</td>\n",
       "      <td>149</td>\n",
       "      <td>[President, Obama, policies, create, problems,...</td>\n",
       "      <td>president obamas policies has not created any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Loving &lt;e&gt;Obama&lt;/e&gt;'s &lt;a&gt;defense of immigratio...</td>\n",
       "      <td>52</td>\n",
       "      <td>[Loving, Obama, defense, immigration]</td>\n",
       "      <td>loving obamas defense of immigration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  tweet_length  \\\n",
       "3   Ditto. I started @247LS 4 years ago. RT @bmorr...           146   \n",
       "4   I absolutely love <e>Obama</e>'s view in <a>im...           125   \n",
       "5   I'm agreeing completely with <e>Obama</e>'s st...           132   \n",
       "6         <e>Obama</e>'s <a>smile</a> makes me happy.            43   \n",
       "7   Hahahahahaahahha<e> Obama</e>'s <a>rebuttal</a...            83   \n",
       "8   If you think the economy has gotten worse duri...           153   \n",
       "9   <e>Obama</e>'s <a>debate performance</a> tonig...            91   \n",
       "10  I like the fact that it's not within <e>Obama<...            76   \n",
       "11  President <e>Obama</e>'s <a>policies</a> HAS N...           149   \n",
       "12  Loving <e>Obama</e>'s <a>defense of immigratio...            52   \n",
       "\n",
       "                                        tweet_cleaned  \\\n",
       "3   [Ditto, start, years, ago, RT, bmorrissey, wor...   \n",
       "4   [absolutely, love, Obama, view, immigration, r...   \n",
       "5   [agree, completely, Obama, stance, immigration...   \n",
       "6                         [Obama, smile, make, happy]   \n",
       "7   [Hahahahahaahahha, Obama, rebuttal, get, actua...   \n",
       "8   [think, economy, get, worse, Obama, term, plea...   \n",
       "9   [Obama, debate, performance, tonight, better, ...   \n",
       "10   [like, fact, within, Obama, comfort, zone, rude]   \n",
       "11  [President, Obama, policies, create, problems,...   \n",
       "12              [Loving, Obama, defense, immigration]   \n",
       "\n",
       "                                           tweet_clst  \n",
       "3   ditto i started 4 years ago rt i work for a sm...  \n",
       "4   i absolutely love obamas view in immigration h...  \n",
       "5   im agreeing completely with obamas stance on i...  \n",
       "6                         obamas smile makes me happy  \n",
       "7   hahahahahaahahha obamas rebuttal got actual cr...  \n",
       "8   if you think the economy has gotten worse duri...  \n",
       "9   obamas debate performance tonight about 100000...  \n",
       "10  i like the fact that its not within obamas com...  \n",
       "11  president obamas policies has not created any ...  \n",
       "12               loving obamas defense of immigration  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_obama['tweet_clst'] = clean_data(df_obama['tweet'])\n",
    "df_obama['tweet_clst'] = df_obama['tweet_clst'].apply(lambda x: ','.join(x))\n",
    "df_obama['tweet_clst'] = df_obama['tweet_clst'].apply(lambda x: x.replace(',' , ' '))\n",
    "df_obama.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>tweet_clst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I actually like  &lt;e&gt;Romney &lt;/e&gt;'s response to ...</td>\n",
       "      <td>58</td>\n",
       "      <td>[actually, like, Romney, response, immigration]</td>\n",
       "      <td>i actually like romney s response to immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just for that &lt;a&gt;immigration statement &lt;/a&gt;tha...</td>\n",
       "      <td>115</td>\n",
       "      <td>[immigration, statement, Romney, answer, enoug...</td>\n",
       "      <td>just for that immigration statement that romne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This man  &lt;e&gt;Romney  &lt;/e&gt;is tearing this dude ...</td>\n",
       "      <td>68</td>\n",
       "      <td>[man, Romney, tear, dude, economics]</td>\n",
       "      <td>this man romney is tearing this dude up on eco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;e&gt;Romney  &lt;/e&gt;had less to prove, given the la...</td>\n",
       "      <td>108</td>\n",
       "      <td>[Romney, less, prove, give, last, debate, back...</td>\n",
       "      <td>romney had less to prove given the last debate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;e&gt;Romney &lt;/e&gt;- he comes off as a dumbass, but...</td>\n",
       "      <td>160</td>\n",
       "      <td>[Romney, come, dumbass, love, plan, small, lar...</td>\n",
       "      <td>romney he comes off as a dumbass but i love hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Great &lt;a&gt;closing&lt;/a&gt; by  &lt;e&gt;Romney &lt;/e&gt;. Summe...</td>\n",
       "      <td>77</td>\n",
       "      <td>[Great, close, Romney, Summed, well, debate]</td>\n",
       "      <td>great closing by romney summed it all up very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Just ready for  &lt;e&gt;Romney &lt;/e&gt; to become presi...</td>\n",
       "      <td>54</td>\n",
       "      <td>[ready, Romney, become, president, lol]</td>\n",
       "      <td>just ready for romney to become president lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Get him on his trampling on the Constitution, ...</td>\n",
       "      <td>65</td>\n",
       "      <td>[Get, trample, Constitution, Mitt, Please]</td>\n",
       "      <td>get him on his trampling on the constitution m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Go &lt;e&gt;Romney&lt;/e&gt;!!! I'm tired of all this &lt;a&gt;i...</td>\n",
       "      <td>68</td>\n",
       "      <td>[Go, Romney, tire, immigration, shit]</td>\n",
       "      <td>go romney im tired of all this immigration shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;e&gt;Romney&lt;/e&gt; is the shit you people are crazy</td>\n",
       "      <td>46</td>\n",
       "      <td>[Romney, shit, people, crazy]</td>\n",
       "      <td>romney is the shit you people are crazy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  tweet_length  \\\n",
       "3   I actually like  <e>Romney </e>'s response to ...            58   \n",
       "4   Just for that <a>immigration statement </a>tha...           115   \n",
       "5   This man  <e>Romney  </e>is tearing this dude ...            68   \n",
       "6   <e>Romney  </e>had less to prove, given the la...           108   \n",
       "7   <e>Romney </e>- he comes off as a dumbass, but...           160   \n",
       "8   Great <a>closing</a> by  <e>Romney </e>. Summe...            77   \n",
       "9   Just ready for  <e>Romney </e> to become presi...            54   \n",
       "10  Get him on his trampling on the Constitution, ...            65   \n",
       "11  Go <e>Romney</e>!!! I'm tired of all this <a>i...            68   \n",
       "12     <e>Romney</e> is the shit you people are crazy            46   \n",
       "\n",
       "                                        tweet_cleaned  \\\n",
       "3     [actually, like, Romney, response, immigration]   \n",
       "4   [immigration, statement, Romney, answer, enoug...   \n",
       "5                [man, Romney, tear, dude, economics]   \n",
       "6   [Romney, less, prove, give, last, debate, back...   \n",
       "7   [Romney, come, dumbass, love, plan, small, lar...   \n",
       "8        [Great, close, Romney, Summed, well, debate]   \n",
       "9             [ready, Romney, become, president, lol]   \n",
       "10         [Get, trample, Constitution, Mitt, Please]   \n",
       "11              [Go, Romney, tire, immigration, shit]   \n",
       "12                      [Romney, shit, people, crazy]   \n",
       "\n",
       "                                           tweet_clst  \n",
       "3    i actually like romney s response to immigration  \n",
       "4   just for that immigration statement that romne...  \n",
       "5   this man romney is tearing this dude up on eco...  \n",
       "6   romney had less to prove given the last debate...  \n",
       "7   romney he comes off as a dumbass but i love hi...  \n",
       "8   great closing by romney summed it all up very ...  \n",
       "9       just ready for romney to become president lol  \n",
       "10  get him on his trampling on the constitution m...  \n",
       "11    go romney im tired of all this immigration shit  \n",
       "12            romney is the shit you people are crazy  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_romney['tweet_clst'] = clean_data(df_romney['tweet'])\n",
    "df_romney['tweet_clst'] = df_romney['tweet_clst'].apply(lambda x: ','.join(x))\n",
    "df_romney['tweet_clst'] = df_romney['tweet_clst'].apply(lambda x: x.replace(',' , ' '))\n",
    "df_romney.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_romney.to_csv('cleaned_romney.csv')\n",
    "df_obama.to_csv('cleaned_obama.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(x):\n",
    "  new_tweet = clean_sentence(x)\n",
    "  no_punc_tweet = clean_stopwords(new_tweet)\n",
    "  return normalization(no_punc_tweet)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(df_obama['tweet'], df_obama['class'], test_size=0.1)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "\n",
    "\n",
    "predictions = pipeline.predict(msg_test)\n",
    "\n",
    "print(classification_report(predictions,label_test))\n",
    "print ('\\n')\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_processing)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', SGDClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(df_obama['tweet'], df_obama['class'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "\n",
    "\n",
    "predictions = pipeline.predict(msg_test)\n",
    "\n",
    "print(classification_report(predictions,label_test))\n",
    "print ('\\n')\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "413a07e1ad969ecf435029fab0e4751808051d0f566828a98f3858fc730aecfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
